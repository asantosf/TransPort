{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50cc6b2",
   "metadata": {},
   "source": [
    "# Modelos de Regresión de PySpark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d62057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e157ef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('Models') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178563d",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8e9e6",
   "metadata": {},
   "source": [
    "La regresión lineal es una de las técnicas más usadas en Machine Learning. Su fortaleza estriba en su simplicidad e interpretabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46779f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.32292516677405936,-0.3438548034562218,1.9156017023458414,0.05288058680386263,0.765962720459771,0.0,-0.15105392669186682,-0.21587930360904642,0.22025369188813426]\n",
      "Intercept: 0.1598936844239736\n",
      "numIterations: 7\n",
      "objectiveHistory: [0.49999999999999994, 0.4967620357443381, 0.4936361664340463, 0.4936351537897608, 0.4936351214177871, 0.49363512062528014, 0.4936351206216114]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -9.889232683103197|\n",
      "|  0.5533794340053554|\n",
      "|  -5.204019455758823|\n",
      "| -20.566686715507508|\n",
      "|    -9.4497405180564|\n",
      "|  -6.909112502719486|\n",
      "|  -10.00431602969873|\n",
      "|   2.062397807050484|\n",
      "|  3.1117508432954772|\n",
      "| -15.893608229419382|\n",
      "|  -5.036284254673026|\n",
      "|   6.483215876994333|\n",
      "|  12.429497299109002|\n",
      "|  -20.32003219007654|\n",
      "| -2.0049838218725005|\n",
      "| -17.867901734183793|\n",
      "|   7.646455887420495|\n",
      "| -2.2653482182417406|\n",
      "|-0.10308920436195645|\n",
      "|  -1.380034070385301|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.189077\n",
      "r2: 0.022861\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/sample_linear_regression_data.txt\")\n",
    "\n",
    "lr = LinearRegression(maxIter=10, \n",
    "                      regParam=0.3, \n",
    "                      elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6eacce",
   "metadata": {},
   "source": [
    "### Regresión lineal generalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71859bd2",
   "metadata": {},
   "source": [
    "En contraste con la regresión lineal donde se supone que la salida sigue una distribución gaussiana, los modelos lineales generalizados (GLM) son especificaciones de modelos lineales donde la variable de respuesta YI sigue alguna distribución de la familia exponencial de distribuciones. La  interfaz de Spark **GeneralizedLinearRegression** permite la especificación flexible de GLM que se pueden utilizar para varios tipos de problemas de predicción, incluida la regresión lineal, la regresión de Poisson, la regresión logística y otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6de1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.010541828081257216,0.8003253100560949,-0.7845165541420371,2.3679887171421914,0.5010002089857577,1.1222351159753026,-0.2926824398623296,-0.49837174323213035,-0.6035797180675657,0.6725550067187461]\n",
      "Intercept: 0.14592176145232041\n",
      "Coefficient Standard Errors: [0.7950428434287478, 0.8049713176546897, 0.7975916824772489, 0.8312649247659919, 0.7945436200517938, 0.8118992572197593, 0.7919506385542777, 0.7973378214726764, 0.8300714999626418, 0.7771333489686802, 0.463930109648428]\n",
      "T Values: [0.013259446542269243, 0.9942283563442594, -0.9836067393599172, 2.848657084633759, 0.6305509179635714, 1.382234441029355, -0.3695715687490668, -0.6250446546128238, -0.7271418403049983, 0.8654306337661122, 0.31453393176593286]\n",
      "P Values: [0.989426199114056, 0.32060241580811044, 0.3257943227369877, 0.004575078538306521, 0.5286281628105467, 0.16752945248679119, 0.7118614002322872, 0.5322327097421431, 0.467486325282384, 0.3872259825794293, 0.753249430501097]\n",
      "Dispersion: 105.60988356821714\n",
      "Null Deviance: 53229.3654338832\n",
      "Residual Degree Of Freedom Null: 500\n",
      "Deviance: 51748.8429484264\n",
      "Residual Degree Of Freedom: 490\n",
      "AIC: 3769.1895871765314\n",
      "Deviance Residuals: \n",
      "+-------------------+\n",
      "|  devianceResiduals|\n",
      "+-------------------+\n",
      "|-10.974359174246889|\n",
      "| 0.8872320138420559|\n",
      "| -4.596541837478908|\n",
      "|-20.411667435019638|\n",
      "|-10.270419345342642|\n",
      "|-6.0156058956799905|\n",
      "|-10.663939415849267|\n",
      "| 2.1153960525024713|\n",
      "| 3.9807132379137675|\n",
      "|-17.225218272069533|\n",
      "| -4.611647633532147|\n",
      "| 6.4176669407698546|\n",
      "| 11.407137945300537|\n",
      "| -20.70176540467664|\n",
      "| -2.683748540510967|\n",
      "|-16.755494794232536|\n",
      "|  8.154668342638725|\n",
      "|-1.4355057987358848|\n",
      "|-0.6435058688185704|\n",
      "|  -1.13802589316832|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Load training data\n",
    "dataset = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/sample_linear_regression_data.txt\")\n",
    "\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\", maxIter=10, regParam=0.3)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(dataset)\n",
    "\n",
    "# Print the coefficients and intercept for generalized linear regression model\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "summary = model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))\n",
    "print(\"Dispersion: \" + str(summary.dispersion))\n",
    "print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "print(\"Deviance: \" + str(summary.deviance))\n",
    "print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "print(\"AIC: \" + str(summary.aic))\n",
    "print(\"Deviance Residuals: \")\n",
    "summary.residuals().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441b18f",
   "metadata": {},
   "source": [
    "### Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb46efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[125,126,127...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0\n",
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_e27761e313ee, depth=2, numNodes=5, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, \n",
    "                            dt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "treeModel = model.stages[1]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b3f6f",
   "metadata": {},
   "source": [
    "### Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8c0fe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[98,99,100,1...|\n",
      "|       0.2|  0.0|(692,[100,101,102...|\n",
      "|       0.1|  0.0|(692,[122,123,148...|\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|      0.05|  0.0|(692,[123,124,125...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.1\n",
      "RandomForestRegressionModel: uid=RandomForestRegressor_32474d2eeae3, numTrees=20, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexer and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, \n",
    "                            rf])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "rfModel = model.stages[1]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e21d293",
   "metadata": {},
   "source": [
    "### Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791dfd38",
   "metadata": {},
   "source": [
    "Los árboles potenciados por gradientes (GBT) son un método de regresión popular que utiliza conjuntos de árboles de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7041636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[125,126,127...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0\n",
      "GBTRegressionModel: uid=GBTRegressor_61148d8280d6, numTrees=10, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(featuresCol=\"indexedFeatures\", \n",
    "                   maxIter=10)\n",
    "\n",
    "# Chain indexer and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, \n",
    "                            gbt])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "gbtModel = model.stages[1]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a712b9",
   "metadata": {},
   "source": [
    "### Survival regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5e7c96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.4963111466650693,0.1984443769993358]\n",
      "Intercept: 2.638094615104007\n",
      "Scale: 1.547234557436469\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|label|censor|features      |prediction        |quantiles                              |\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|1.218|1.0   |[1.56,-0.605] |5.718979487634984 |[1.160323894715161,4.99545601027475]   |\n",
      "|2.949|0.0   |[0.346,2.158] |18.076521181495465|[3.6675458454717638,15.789611866277742]|\n",
      "|3.627|0.0   |[1.38,0.231]  |7.381861804239096 |[1.497706130519082,6.44796261233896]   |\n",
      "|0.273|1.0   |[0.52,1.151]  |13.577612501425325|[2.754762148150692,11.859872224069736] |\n",
      "|4.199|0.0   |[0.795,-0.226]|9.013097744073871 |[1.828667632129776,7.872826505878406]  |\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import AFTSurvivalRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "training = spark.createDataFrame([\n",
    "    (1.218, 1.0, Vectors.dense(1.560, -0.605)),\n",
    "    (2.949, 0.0, Vectors.dense(0.346, 2.158)),\n",
    "    (3.627, 0.0, Vectors.dense(1.380, 0.231)),\n",
    "    (0.273, 1.0, Vectors.dense(0.520, 1.151)),\n",
    "    (4.199, 0.0, Vectors.dense(0.795, -0.226))], [\"label\", \"censor\", \"features\"])\n",
    "\n",
    "quantileProbabilities = [0.3, 0.6]\n",
    "\n",
    "aft = AFTSurvivalRegression(quantileProbabilities=quantileProbabilities,\n",
    "                            quantilesCol=\"quantiles\")\n",
    "\n",
    "model = aft.fit(training)\n",
    "\n",
    "# Print the coefficients, intercept and scale parameter for AFT survival regression\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))\n",
    "print(\"Scale: \" + str(model.scale))\n",
    "\n",
    "model.transform(training).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360554d4",
   "metadata": {},
   "source": [
    "### Factorization machines regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eb256",
   "metadata": {},
   "source": [
    "Es un algoritmo de aprendizaje supervisado de propósito general que puede usar para tareas de clasificación y regresión. Es una extensión de un modelo lineal que está diseñado para **capturar interacciones** entre características dentro de datasets dispersos de alta dimensión de manera efectiva. \n",
    "\n",
    "Son una buena opción para tareas relacionadas con **conjuntos de datos dispersos de alta dimensión**, como la predicción de clics y la recomendación de productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2adc9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          prediction|label|            features|\n",
      "+--------------------+-----+--------------------+\n",
      "|-0.11498417849481646|  0.0|(692,[123,124,125...|\n",
      "|-0.04500884698267623|  0.0|(692,[124,125,126...|\n",
      "|-0.02517267297718...|  0.0|(692,[124,125,126...|\n",
      "|-0.06398956291051354|  0.0|(692,[124,125,126...|\n",
      "|0.021300249312980774|  0.0|(692,[126,127,128...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.137464\n",
      "Factors: DenseMatrix([[ 0.00717793, -0.00775907,  0.00066921, ...,  0.00528039,\n",
      "               0.0056748 ,  0.02244153],\n",
      "             [-0.00040321, -0.0050271 ,  0.00884098, ..., -0.01271648,\n",
      "               0.00545319,  0.00963043],\n",
      "             [-0.00446365,  0.01150839,  0.0003203 , ..., -0.00360363,\n",
      "               0.00640466,  0.00047152],\n",
      "             ...,\n",
      "             [ 0.00196553, -0.00544544, -0.00320827, ...,  0.00607524,\n",
      "               0.02273073, -0.01315482],\n",
      "             [-0.01335745,  0.01660226,  0.00237519, ...,  0.01837403,\n",
      "               0.0050277 ,  0.00097566],\n",
      "             [-0.02994549,  0.00080167, -0.00087455, ...,  0.00784379,\n",
      "               0.01082944,  0.02165324]])\n",
      "Linear: [0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.01020119085489186,-0.01020119085489186,0.008865680119020064,0.0270121199764807,0.006341753443437512,-0.012411695579902432,-0.01361008703737394,-0.005311777968411192,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.017809298038342275,0.01780929803834227,0.0154268429817559,-0.007324672180596983,-0.001865429677891742,-0.0015821654481510874,-0.0040038990022158655,-0.001771048878893919,-0.0035610613728723935,-0.006173469087278104,-0.009728208058661966,-0.00151397937986868,0.01014908873498364,0.006205285128022932,-0.01617956066580158,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.017809298038342275,0.017809298038342275,0.016806127055832797,0.009100039757829644,-0.00498089831234808,-0.008535284914138607,-0.0028547177294484787,-0.007454818410137653,-0.00899709895040266,-0.006909274208890436,-0.00531166547899754,-0.004020009327117946,-0.002666266467751135,0.0009023370147332929,-0.0003943542330429162,-0.007768051983038476,-0.016302746888113062,-0.016561434143034362,-0.016561434143034362,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.017809298038342275,0.01504436279571966,0.005940349494727258,-0.0014939237940320134,-0.006167695889362415,-0.007864548573648652,-0.007980712714610896,-0.007958916498948488,-0.006811912090971467,-0.002958053089453939,-0.002535036044855557,-0.003813514803709714,-0.0035402591935097144,-0.003639585912928504,-0.006287951517390501,-0.007139483334532296,-0.012660723286120733,-0.016561434143034362,-0.016561434143034362,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.0035548389882734074,0.0021472823061692227,-0.0018448234724928489,-0.0048044768963727376,-0.005867584045226855,-0.009400275863677298,-0.007982468570409608,-0.005341790227501625,-0.0030065418220981115,0.00034167595159447536,-0.0007840488429616334,-0.00588637764410942,-0.005170629217273376,-0.005697828474285136,-0.004978526436239665,-0.001234272231002442,-0.0068952810268902995,-0.016334791748982783,-0.016561434143034362,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.008222116020427876,-0.00926237484297911,-0.006839468478779933,-0.006175012623244428,-0.007108331268889781,-0.007948084952698907,-0.008066432937997017,-0.0037126031880357693,-0.0016412893530489577,-0.0008530250306111161,0.0007364756338422996,-0.001432877215982738,-0.0030898013315866055,-0.005610995481671907,-0.008047290050483059,-0.007106709418308152,-0.006594078994109585,-0.006233818145363557,-0.014098978408492462,-0.016561434143034362,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.011246146989375419,-0.00973876360327907,-0.008269037771084483,-0.010370939381022744,-0.007452214337131105,-0.0068358759400640135,-0.007969520622079208,-0.0019399190276632508,-0.0010465008425041408,-0.0007250615260240825,0.0018750675474335289,0.0005458861255621591,-0.00018268735617417913,-0.0028205157469264838,-0.009236389931178932,-0.010101624400728558,-0.011577348154390408,-0.011454263341003626,-0.010843681577983478,-0.016561434143034362,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.00956241402022207,-0.010552252801190092,-0.010258863899281014,-0.00817518107192614,-0.006908286489818378,-0.008560976914651318,-0.007933223767304917,-0.004482830790659365,-0.0013355525519680401,0.004427690293911315,0.0055479464712387475,0.003782177533945975,0.004264202321459121,-0.0008432136840594202,-0.008624400183156338,-0.011627928680124213,-0.011377045425612138,-0.012411234174400184,-0.01338321299629335,-0.01758234338339704,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.010730108624605411,-0.010038072049956914,-0.007748809401469316,-0.006162361049737938,-0.008675589144513291,-0.0093080057185634,-0.011001609224976464,-0.008383964221248779,0.003049030786263735,0.007655000502802996,0.007397244904143441,0.007037249780298001,0.007511126041471922,0.003449605755737506,-0.012465715484149271,-0.012393578576315194,-0.01065051924765315,-0.011298894812347436,-0.012953095904563497,-0.01876541229665619,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.012098574696537358,-0.008205617562235272,-0.005548735705708291,-0.007807681743483927,-0.011006832315046643,-0.01205958034380745,-0.011259243746589953,-0.006795340167671644,0.0066403879194570515,0.009083508846228128,0.008571581070050202,0.008769675901821516,0.0077743336392607715,-0.005001657019985848,-0.015545665162613497,-0.012560680743385644,-0.011424344224819473,-0.010790582794936145,-0.011964729972415957,-0.014048078079772089,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.010816500962247136,-0.005637099468865544,-0.007167819153955742,-0.011642549477295016,-0.012841308572656715,-0.013007368290925834,-0.013046676329884613,-0.004301484565541853,0.00777703466430531,0.009754757054854613,0.008784011638421128,0.008544538601048025,0.011488719095083642,-0.012929436916439573,-0.015080388158843184,-0.013005930190322838,-0.011653598069947032,-0.010666233054251587,-0.011279423947403612,-0.012942013827147535,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.012573105417395753,-0.008051710832098255,-0.009233893506985157,-0.010321718687674132,-0.01241136698381021,-0.013686576590511304,-0.013505615339629585,-0.01318433961725109,0.0050049979272226664,0.00927505443892477,0.009851203737352699,0.009344764288420569,0.008032157689897295,0.010264768527448459,-0.01422068021862549,-0.01418221919019791,-0.013763083950301316,-0.012444555016208298,-0.010425116852104416,-0.011236997105729042,-0.012699152583054754,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.012573105417395753,-0.014592273925373893,-0.010735674376269369,-0.01067661413835118,-0.012088983924338704,-0.013466382663719573,-0.013781401164578447,-0.0065902864124170145,0.006781988862687805,0.00961829938290895,0.010785993045470461,0.008673343600175984,0.013227973168654561,-0.002258903546307837,-0.010956574525145833,-0.013385026656621418,-0.013484358489044335,-0.011673363015598858,-0.011008157424488733,-0.012143119352260794,-0.012204580877532338,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.012573105417395753,-0.013380496146298606,-0.010954521280754364,-0.010648182746928506,-0.011875408406252558,-0.012867834831234822,-0.01216136761455034,0.0031063401441854942,0.007861793949997262,0.009329370042018033,0.010064741047003585,0.00674183000886299,0.009284735102892063,-0.0016474134189591945,-0.011117795536017777,-0.01223107728151415,-0.012555339576379741,-0.012158296607175524,-0.012031418994028176,-0.011061267830929672,-0.009757025274631414,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.014355646238959806,-0.013411984866317676,-0.011259375328415599,-0.010502462587910242,-0.012097759698675247,-0.012681164619603238,-0.009522610423489586,0.0060369858909826496,0.006855149520673077,0.009119557384525816,0.008984881394683049,0.008463382645699362,0.008700508405411514,-0.008355718202350482,-0.010102528202120405,-0.009662099293466593,-0.01159365615112932,-0.012363226275230652,-0.010886413760303432,-0.010211040296052359,-0.01078347230138615,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.016694619588660524,-0.0118224783656635,-0.01228096839409772,-0.010671250592525027,-0.011815246444874876,-0.012971833667017329,-0.0012932443130071896,0.005276817635386223,0.00790165510456387,0.009288819277398937,0.008489514770850004,0.0091657880267193,0.00030077030645788685,-0.010951384934572454,-0.009876959422715203,-0.009975559638897903,-0.01081712096976985,-0.011326901890210326,-0.010302043745276103,-0.00982737422269195,-0.009210122388529182,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.017191684245282755,-0.013157900882763949,-0.012266291872260054,-0.011335978085654397,-0.011753024648220207,-0.010494284058942937,-0.0030299450602178854,0.002430375876654775,0.006714543319832037,0.006717499279356943,0.00577281566490512,0.0020613089465825406,-0.004820290169845784,-0.008504036564705886,-0.007767524834749423,-0.007342209717119342,-0.010177579837653477,-0.01102837655885707,-0.012296758349181572,-0.010091556689758214,-0.00871478037071744,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.018011880492098214,-0.01399805301278625,-0.011447960978860638,-0.010540389141530175,-0.0108617747378108,-0.010276479186444022,-0.006356965195879356,-0.0018768246455422586,-0.0006556403716453395,-0.0006469367348031995,0.0007987152789258067,-0.0033010872007733297,-0.005536564607482717,-0.006216501442792289,-0.0020968688799013584,-0.009559445119199563,-0.009745643148957846,-0.009937811039058074,-0.011284426998706425,-0.011883405306884764,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0,-0.01795435501195181,-0.004650285769481782,-0.007174769485854574,-0.007809395665747713,-0.007431420378979242,-0.00411296682421473,-0.0024328913018275573,-0.00394022242046435,-0.0018230579221127433,-0.0024492361844999297,-0.0028647165749140016,-0.004044326704759979,-0.0039321017927799375,-0.00708292282290718,-0.010383298719205517,-0.008851196122783562,-0.007423045679034729,-0.01036293284624889,-0.011831974420460729,0.0022620291674419,0.0022620291674419,-0.0012131421526756661,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0,-0.018543329603633106,0.009817989429724127,-0.0007494099602791163,-0.0020574778032438333,-0.0018768462418778148,-0.0025305559321554837,-0.0016337796381153227,-0.004307162064995696,-0.003875836830959391,-0.004060548048632522,-0.004281131377038685,-0.006294910484120273,-0.008178851419914066,-0.009490613378236788,-0.005409619855207833,-0.0029125380395977544,0.0005497323938059956,-0.012594337256162623,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0,-0.013638513826153508,0.002981345131166025,0.0028191670090475787,0.003735049207415864,-0.00024320937831273973,-0.0048033745098741,-0.006815235388008322,-0.009091007287920514,-0.008256355026363639,-0.009659501903098314,-0.011134929271318969,-0.007744406922427454,-0.005865174232272335,-0.002356289385963327,0.005634092375535915,0.01522777439581655,-0.012537263727583407,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,0.0022620291674419,-0.018543363916101323,-0.018543362998766244,-0.017182701573299645,0.006059551621329793,0.003589504271653374,-0.004618726111766637,-0.011996327672980832,-0.012546162092215788,-0.007997023878764692,-0.007376517635587583,-0.01276686396406984,-0.010435321609790047,-0.011175149719236027,-0.013566481534728149]\n",
      "Intercept: 0.002262029202849877\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import FMRegressor\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"data/sample_libsvm_data.txt\")\n",
    "\n",
    "# Scale features.\n",
    "featureScaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\").fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a FM model.\n",
    "fm = FMRegressor(featuresCol=\"scaledFeatures\", \n",
    "                 stepSize=0.001)\n",
    "\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=[featureScaler, \n",
    "                            fm])\n",
    "\n",
    "# Train model.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "fmModel = model.stages[1]\n",
    "print(\"Factors: \" + str(fmModel.factors))  # type: ignore\n",
    "print(\"Linear: \" + str(fmModel.linear))  # type: ignore\n",
    "print(\"Intercept: \" + str(fmModel.intercept))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d52ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
